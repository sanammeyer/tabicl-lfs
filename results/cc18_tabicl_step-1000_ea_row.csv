task_id,dataset_id,dataset_name,fold,task_type,n_rows,n_features,n_classes,imbalance_ratio,accuracy,f1_macro,f1_micro,precision_macro,recall_macro,roc_auc,log_loss,fit_seconds,predict_seconds,n_train,n_test,seed,n_valid_folds,error
3,3.0,kr-vs-kp,0.0,Binary,3196.0,36.0,2.0,1.0929927963326784,0.99375,0.993734335839599,0.99375,0.9940828402366864,0.9934640522875817,0.9999217251770968,0.02441041659377157,0.7126236420008354,6.516790293004306,2876.0,320.0,42,10,
3,3.0,kr-vs-kp,1.0,Binary,3196.0,36.0,2.0,1.0929927963326784,0.984375,0.9843565150226341,0.984375,0.9841307066916822,0.9847559782395993,0.9985910531877422,0.04919452643699225,0.5338176209988887,6.647101852999185,2876.0,320.0,42,10,
3,3.0,kr-vs-kp,2.0,Binary,3196.0,36.0,2.0,1.0929927963326784,0.990625,0.9906043552728163,0.990625,0.9907581453634086,0.9904700403115339,0.9982779538961293,0.03980477407081872,0.49578638600360136,6.394575653001084,2876.0,320.0,42,10,
3,3.0,kr-vs-kp,3.0,Binary,3196.0,36.0,2.0,1.0929927963326784,0.996875,0.9968698340033845,0.996875,0.9967532467532467,0.9970059880239521,1.0,0.023025962223957912,0.5151186009970843,6.669815861998359,2876.0,320.0,42,10,
3,3.0,kr-vs-kp,4.0,Binary,3196.0,36.0,2.0,1.0929927963326784,1.0,1.0,1.0,1.0,1.0,1.0,0.009555041855505276,0.5406056249994435,6.5056871339984355,2876.0,320.0,42,10,
3,3.0,kr-vs-kp,5.0,Binary,3196.0,36.0,2.0,1.0929927963326784,1.0,1.0,1.0,1.0,1.0,1.0,0.014426780751345703,0.5111474170043948,6.593954468000447,2876.0,320.0,42,10,
3,3.0,kr-vs-kp,6.0,Binary,3196.0,36.0,2.0,1.0929927963326784,0.987460815047022,0.9874251024913276,0.987460815047022,0.9882352941176471,0.9869281045751634,0.9987006850933144,0.041147716455320296,0.4461348199984059,6.513610524998512,2877.0,319.0,42,10,
3,3.0,kr-vs-kp,7.0,Binary,3196.0,36.0,2.0,1.0929927963326784,0.9905956112852664,0.9905655727200134,0.9905956112852664,0.9911764705882353,0.9901315789473684,0.9995272612669398,0.03728549703599226,0.49076584299473325,6.184763261000626,2877.0,319.0,42,10,
3,3.0,kr-vs-kp,8.0,Binary,3196.0,36.0,2.0,1.0929927963326784,0.9937304075235109,0.9937125512456638,0.9937304075235109,0.9940828402366864,0.993421052631579,0.9999212102111565,0.024988807301365136,0.5154010640035267,6.604460848997405,2877.0,319.0,42,10,
3,3.0,kr-vs-kp,9.0,Binary,3196.0,36.0,2.0,1.0929927963326784,0.9968652037617555,0.9968591542362034,0.9968652037617555,0.9967320261437909,0.9970059880239521,0.9999606051055784,0.017283080951581046,0.5030843280037516,6.724572874998557,2877.0,319.0,42,10,
6,6.0,letter,,,20000.0,16.0,26.0,1.1076294277929155,,,,,,,,,,,,42,0,"Dataset has 20000 rows, exceeds limit of 10000"
11,11.0,balance-scale,0.0,Multiclass,625.0,4.0,3.0,5.877551020408164,0.9682539682539683,0.9327485380116959,0.9682539682539683,0.9047619047619048,0.9770114942528737,0.9977011494252874,0.06987298399249364,0.47584530399763025,0.2770274590002373,562.0,63.0,42,10,
11,11.0,balance-scale,1.0,Multiclass,625.0,4.0,3.0,5.877551020408164,0.9523809523809523,0.9053242079557869,0.9523809523809523,0.875,0.9655172413793104,0.9930358350236647,0.13468558602429043,0.35359074999723816,0.28277546699973755,562.0,63.0,42,10,
11,11.0,balance-scale,2.0,Multiclass,625.0,4.0,3.0,5.877551020408164,0.9523809523809523,0.9048951048951048,0.9523809523809523,0.875,0.9655172413793104,0.9950642325895876,0.1004586586366455,0.3778649009982473,0.2829437569962465,562.0,63.0,42,10,
11,11.0,balance-scale,3.0,Multiclass,625.0,4.0,3.0,5.877551020408164,0.9523809523809523,0.9048951048951048,0.9523809523809523,0.875,0.9655172413793104,0.9963488843813387,0.1407295709142177,0.3457994510026765,0.275734899994859,562.0,63.0,42,10,
11,11.0,balance-scale,4.0,Multiclass,625.0,4.0,3.0,5.877551020408164,0.9682539682539683,0.9325396825396827,0.9682539682539683,0.9047619047619048,0.9770114942528735,0.9986477349560513,0.10924813896686993,0.4385757519994513,0.27472280700021656,562.0,63.0,42,10,
11,11.0,balance-scale,5.0,Multiclass,625.0,4.0,3.0,5.877551020408164,0.9516129032258065,0.890909090909091,0.9516129032258065,0.8571428571428571,0.9655172413793104,0.9882009752699408,0.12378267326859341,0.3522868540021591,0.2786926740009221,563.0,62.0,42,10,
11,11.0,balance-scale,6.0,Multiclass,625.0,4.0,3.0,5.877551020408164,0.9193548387096774,0.8581369248035915,0.9193548387096774,0.8333333333333334,0.9421182266009852,0.9858787781735364,0.2016317940359399,0.35541959699912695,0.2753346609970322,563.0,62.0,42,10,
11,11.0,balance-scale,7.0,Multiclass,625.0,4.0,3.0,5.877551020408164,0.9354838709677419,0.8791208791208792,0.9354838709677419,0.8518518518518517,0.9523809523809524,0.9976608187134502,0.11528841116962997,0.36596488099894486,0.2736133200014592,563.0,62.0,42,10,
11,11.0,balance-scale,8.0,Multiclass,625.0,4.0,3.0,5.877551020408164,0.9516129032258065,0.9051115551115552,0.9516129032258065,0.875,0.9651067323481116,0.9924104933179342,0.13562531268005504,0.36193868999544065,0.272782106003433,563.0,62.0,42,10,
11,11.0,balance-scale,9.0,Multiclass,625.0,4.0,3.0,5.877551020408164,0.9838709677419355,0.9636363636363635,0.9838709677419355,0.9444444444444445,0.9880952380952381,1.0,0.09218584666461552,0.35469848600041587,0.27539632199477637,563.0,62.0,42,10,
12,12.0,mfeat-factors,0.0,Multiclass,2000.0,216.0,10.0,1.0,0.97,0.9699723041186455,0.97,0.9708589655958078,0.97,0.99975,0.05445158204751622,0.6945498929999303,20.737214212000254,1800.0,200.0,42,10,
12,12.0,mfeat-factors,1.0,Multiclass,2000.0,216.0,10.0,1.0,0.995,0.9949968730456537,0.995,0.9952380952380953,0.9949999999999999,0.9999722222222222,0.0329539647338254,0.6764631149999332,20.949117990996456,1800.0,200.0,42,10,
12,12.0,mfeat-factors,2.0,Multiclass,2000.0,216.0,10.0,1.0,0.985,0.9851067631555436,0.985,0.9861471861471862,0.985,0.9999444444444444,0.04117146621873863,0.7164421209963621,20.963774014999217,1800.0,200.0,42,10,
12,12.0,mfeat-factors,3.0,Multiclass,2000.0,216.0,10.0,1.0,0.97,0.9699754310729919,0.97,0.9711221234905445,0.97,0.9994999999999999,0.10335185348259791,0.6953339489991777,21.067856622001273,1800.0,200.0,42,10,
12,12.0,mfeat-factors,4.0,Multiclass,2000.0,216.0,10.0,1.0,0.975,0.9749744906355946,0.975,0.9761904761904763,0.975,0.9987222222222222,0.11023726468464613,0.6935446810020949,21.072189208003692,1800.0,200.0,42,10,
12,12.0,mfeat-factors,5.0,Multiclass,2000.0,216.0,10.0,1.0,0.98,0.9799906191369606,0.98,0.9807142857142856,0.9799999999999999,0.9999166666666668,0.056887649131230324,0.6826768469982198,21.054834526003106,1800.0,200.0,42,10,
12,12.0,mfeat-factors,6.0,Multiclass,2000.0,216.0,10.0,1.0,0.99,0.9899937460913073,0.99,0.9904761904761905,0.99,1.0,0.03628243203684242,0.6534958429983817,20.942683795998164,1800.0,200.0,42,10,
12,12.0,mfeat-factors,7.0,Multiclass,2000.0,216.0,10.0,1.0,0.97,0.9703027585106577,0.97,0.9731037078863165,0.97,0.9999166666666666,0.06289125719668195,0.6624075530053233,21.19811735500116,1800.0,200.0,42,10,
12,12.0,mfeat-factors,8.0,Multiclass,2000.0,216.0,10.0,1.0,0.99,0.9899968730456535,0.99,0.9902380952380951,0.99,0.9995277777777778,0.06324809355675624,0.8437284030005685,22.84014596400084,1800.0,200.0,42,10,
12,12.0,mfeat-factors,9.0,Multiclass,2000.0,216.0,10.0,1.0,0.98,0.9800000000000001,0.98,0.9800000000000001,0.9800000000000001,0.999861111111111,0.0520157573549481,0.6643418530002236,20.656275781002478,1800.0,200.0,42,10,
14,,N/A,,,,,,,,,,,,,,,,,,42,0,"HIP out of memory. Tried to allocate 3.05 GiB. GPU 0 has a total capacity of 15.98 GiB of which 2.66 GiB is free. Of the allocated memory 12.90 GiB is allocated by PyTorch, and 76.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
15,15.0,breast-w,0.0,Binary,699.0,9.0,2.0,1.900414937759336,0.9714285714285714,0.9688888888888889,0.9714285714285714,0.9615384615384616,0.9782608695652174,0.9981884057971014,0.06329553917588926,0.4173330330013414,0.46908555200207047,629.0,70.0,42,10,
15,15.0,breast-w,1.0,Binary,699.0,9.0,2.0,1.900414937759336,0.9714285714285714,0.9688888888888889,0.9714285714285714,0.9615384615384616,0.9782608695652174,0.9936594202898551,0.08875624596304606,0.4306439619977027,0.4604791970050428,629.0,70.0,42,10,
15,15.0,breast-w,2.0,Binary,699.0,9.0,2.0,1.900414937759336,1.0,1.0,1.0,1.0,1.0,1.0,0.014266856677791736,0.37588104900351027,0.4634683850017609,629.0,70.0,42,10,
15,15.0,breast-w,3.0,Binary,699.0,9.0,2.0,1.900414937759336,0.9428571428571428,0.9388111888111889,0.9428571428571428,0.9285714285714286,0.9565217391304348,1.0,0.08874323859308592,0.4085637129974202,0.46993012000166345,629.0,70.0,42,10,
15,15.0,breast-w,4.0,Binary,699.0,9.0,2.0,1.900414937759336,1.0,1.0,1.0,1.0,1.0,1.0,0.021010112922088264,0.3959700289997272,0.46610566999879666,629.0,70.0,42,10,
15,15.0,breast-w,5.0,Binary,699.0,9.0,2.0,1.900414937759336,0.9714285714285714,0.9682971014492754,0.9714285714285714,0.9682971014492754,0.9682971014492754,0.9927536231884058,0.1404497834678796,0.40273940499901073,0.4660612489969935,629.0,70.0,42,10,
15,15.0,breast-w,6.0,Binary,699.0,9.0,2.0,1.900414937759336,0.9857142857142858,0.9843014128728415,0.9857142857142858,0.98,0.9891304347826086,0.9972826086956522,0.05043128117764757,0.3639657179955975,0.4710476530017331,629.0,70.0,42,10,
15,15.0,breast-w,7.0,Binary,699.0,9.0,2.0,1.900414937759336,0.9285714285714286,0.9215070643642072,0.9285714285714286,0.9177777777777778,0.9257246376811594,0.9882246376811593,0.14694837928931964,0.3839255549974041,0.4652696900011506,629.0,70.0,42,10,
15,15.0,breast-w,8.0,Binary,699.0,9.0,2.0,1.900414937759336,0.9714285714285714,0.9694055944055944,0.9714285714285714,0.962962962962963,0.9777777777777779,0.9893333333333334,0.10749418431866056,0.3832492900037323,0.4675086930001271,629.0,70.0,42,10,
15,15.0,breast-w,9.0,Binary,699.0,9.0,2.0,1.900414937759336,0.9710144927536232,0.9686363636363636,0.9710144927536232,0.9615384615384616,0.9777777777777779,0.9925925925925927,0.09285644095918069,0.39170262099651154,0.45983278199855704,630.0,69.0,42,10,
16,,N/A,,,,,,,,,,,,,,,,,,42,0,"HIP out of memory. Tried to allocate 2.21 GiB. GPU 0 has a total capacity of 15.98 GiB of which 1.46 GiB is free. Of the allocated memory 11.92 GiB is allocated by PyTorch, and 2.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
18,18.0,mfeat-morphological,0.0,Multiclass,2000.0,6.0,10.0,1.0,0.705,0.7005992321292198,0.705,0.6994054677206851,0.7049999999999998,0.9551111111111112,0.8069514779709763,0.3955436379983439,1.5646471439977176,1800.0,200.0,42,10,
18,18.0,mfeat-morphological,1.0,Multiclass,2000.0,6.0,10.0,1.0,0.755,0.7519982122655496,0.755,0.7535688221270063,0.755,0.9649444444444445,0.5769034785752526,0.37801408999803243,1.5679617900023004,1800.0,200.0,42,10,
18,18.0,mfeat-morphological,2.0,Multiclass,2000.0,6.0,10.0,1.0,0.72,0.7111399712580624,0.72,0.7171083099906628,0.72,0.9662499999999999,0.6357414691640522,0.4127117870011716,1.5677755540018552,1800.0,200.0,42,10,
18,18.0,mfeat-morphological,3.0,Multiclass,2000.0,6.0,10.0,1.0,0.74,0.7313006374292719,0.74,0.7392130695391564,0.74,0.9688333333333334,0.5444916132458352,0.4042515800028923,1.5714289280003868,1800.0,200.0,42,10,
18,18.0,mfeat-morphological,4.0,Multiclass,2000.0,6.0,10.0,1.0,0.73,0.7283117738059971,0.73,0.7308847877268929,0.7300000000000001,0.9663333333333334,0.5627911503677852,0.42921033399761654,1.566254226003366,1800.0,200.0,42,10,
18,18.0,mfeat-morphological,5.0,Multiclass,2000.0,6.0,10.0,1.0,0.77,0.7655859113575197,0.77,0.7751601120401964,0.77,0.9780555555555555,0.47364388152247744,0.3928636839991668,1.5676292739954079,1800.0,200.0,42,10,
18,18.0,mfeat-morphological,6.0,Multiclass,2000.0,6.0,10.0,1.0,0.72,0.7169062399124793,0.72,0.7186060259344011,0.72,0.9650555555555556,0.6653843152688123,0.5198218479999923,1.5854649809989496,1800.0,200.0,42,10,
18,18.0,mfeat-morphological,7.0,Multiclass,2000.0,6.0,10.0,1.0,0.755,0.7460806069227122,0.755,0.7551764705882353,0.7550000000000001,0.9761388888888888,0.4815220712661285,0.366768817002594,1.5729467519995524,1800.0,200.0,42,10,
18,18.0,mfeat-morphological,8.0,Multiclass,2000.0,6.0,10.0,1.0,0.72,0.7168344954223167,0.72,0.7336849728203576,0.72,0.9634444444444444,0.665928909185781,0.3736348479942535,1.5686656840043725,1800.0,200.0,42,10,
18,18.0,mfeat-morphological,9.0,Multiclass,2000.0,6.0,10.0,1.0,0.715,0.7079147070982946,0.715,0.7115585461237635,0.715,0.9656388888888887,0.6017828788447493,0.4184795409964863,1.563948444003472,1800.0,200.0,42,10,
22,22.0,mfeat-zernike,0.0,Multiclass,2000.0,47.0,10.0,1.0,0.825,0.8211711053174466,0.825,0.8194554568238779,0.825,0.9792222222222223,0.32057759316755996,0.4755785920060589,4.494170257996302,1800.0,200.0,42,10,
22,22.0,mfeat-zernike,1.0,Multiclass,2000.0,47.0,10.0,1.0,0.825,0.8239080773740592,0.825,0.8251352813852814,0.825,0.9792500000000001,0.27339371450977257,0.4273095259995898,4.55196231300215,1800.0,200.0,42,10,
22,22.0,mfeat-zernike,2.0,Multiclass,2000.0,47.0,10.0,1.0,0.835,0.8344707923655292,0.835,0.8348484848484847,0.835,0.9796666666666667,0.27911829563525076,0.4778737029992044,4.527999496996927,1800.0,200.0,42,10,
22,22.0,mfeat-zernike,3.0,Multiclass,2000.0,47.0,10.0,1.0,0.845,0.8399359649614896,0.845,0.8365819687558818,0.845,0.9813611111111111,0.2657391608589367,0.4711313509978936,4.469437804000336,1800.0,200.0,42,10,
22,22.0,mfeat-zernike,4.0,Multiclass,2000.0,47.0,10.0,1.0,0.8,0.7984185405238037,0.8,0.7991161616161616,0.8,0.9791666666666667,0.2850684104869077,0.4746381449949695,4.560926001002372,1800.0,200.0,42,10,
22,22.0,mfeat-zernike,5.0,Multiclass,2000.0,47.0,10.0,1.0,0.83,0.8203300764276374,0.83,0.815068265068265,0.8299999999999998,0.9821666666666667,0.2986297737190128,0.4906182710037683,4.513556628997321,1800.0,200.0,42,10,
22,22.0,mfeat-zernike,6.0,Multiclass,2000.0,47.0,10.0,1.0,0.855,0.8519893732032132,0.855,0.8502587991718427,0.8550000000000001,0.9818333333333333,0.23720644210948014,0.4961351140009356,4.506880770000862,1800.0,200.0,42,10,
22,22.0,mfeat-zernike,7.0,Multiclass,2000.0,47.0,10.0,1.0,0.8,0.7978086579155332,0.8,0.8001411631846415,0.8,0.9800277777777777,0.30446645189338395,0.43447888499940746,4.52730093900027,1800.0,200.0,42,10,
22,22.0,mfeat-zernike,8.0,Multiclass,2000.0,47.0,10.0,1.0,0.765,0.7581488430268919,0.765,0.7528503075871498,0.765,0.9776666666666667,0.37369949279005,0.43618910999794025,4.485109389002901,1800.0,200.0,42,10,
22,22.0,mfeat-zernike,9.0,Multiclass,2000.0,47.0,10.0,1.0,0.79,0.7859917382574635,0.79,0.7832539682539682,0.79,0.9790277777777778,0.3267879443001462,0.45297424400632735,4.611505688997568,1800.0,200.0,42,10,
23,23.0,cmc,0.0,Multiclass,1473.0,9.0,3.0,1.8888888888888888,0.5945945945945946,0.5689949818239293,0.5945945945945946,0.587123745819398,0.5653594771241829,0.7767295571993794,0.8388085619177674,0.4567719050028245,1.171089399002085,1325.0,148.0,42,10,
23,23.0,cmc,1.0,Multiclass,1473.0,9.0,3.0,1.8888888888888888,0.5202702702702703,0.5082071017222086,0.5202702702702703,0.5188740856844305,0.5054466230936819,0.7242838161369328,0.9217239918275282,0.4493702800027677,1.1668886840052437,1325.0,148.0,42,10,
23,23.0,cmc,2.0,Multiclass,1473.0,9.0,3.0,1.8888888888888888,0.5135135135135135,0.4920084659173843,0.5135135135135135,0.49233395801871627,0.4919078742608154,0.6918555062948796,1.0023917960942008,0.39167326300230343,1.167745366001327,1325.0,148.0,42,10,
23,23.0,cmc,3.0,Multiclass,1473.0,9.0,3.0,1.8888888888888888,0.5306122448979592,0.5074020143186506,0.5306122448979592,0.5076396596374398,0.5075969781852135,0.7115489714404281,0.9526082782374985,0.4106007599984878,1.162655072999769,1326.0,147.0,42,10,
23,23.0,cmc,4.0,Multiclass,1473.0,9.0,3.0,1.8888888888888888,0.5918367346938775,0.5741477272727272,0.5918367346938775,0.5939459214330253,0.567495685142744,0.778117371793658,0.8486982665093458,0.5309542449977016,1.1694405469970661,1326.0,147.0,42,10,
23,23.0,cmc,5.0,Multiclass,1473.0,9.0,3.0,1.8888888888888888,0.5578231292517006,0.5313440528971413,0.5578231292517006,0.5398268398268399,0.5314206490677079,0.7454804799821755,0.9130766998097218,0.37580064699432114,1.16572724100115,1326.0,147.0,42,10,
23,23.0,cmc,6.0,Multiclass,1473.0,9.0,3.0,1.8888888888888888,0.5374149659863946,0.52713379810154,0.5374149659863946,0.5286379275450314,0.5260730554848202,0.7299024031019461,0.9000231380082298,0.3695070690009743,1.172630567001761,1326.0,147.0,42,10,
23,23.0,cmc,7.0,Multiclass,1473.0,9.0,3.0,1.8888888888888888,0.54421768707483,0.5235990488006618,0.54421768707483,0.5266870193350349,0.521913816031463,0.7422560708671204,0.907867746160888,0.3758916720034904,1.1684991919973982,1326.0,147.0,42,10,
23,23.0,cmc,8.0,Multiclass,1473.0,9.0,3.0,1.8888888888888888,0.6190476190476191,0.5974186307519641,0.6190476190476191,0.6002126528442319,0.5970347735053617,0.7502464657668845,0.8866192085247546,0.39337926499865716,1.1654435470045428,1326.0,147.0,42,10,
23,23.0,cmc,9.0,Multiclass,1473.0,9.0,3.0,1.8888888888888888,0.5918367346938775,0.5830536603356077,0.5918367346938775,0.5837316791339779,0.5858711181291826,0.7939696265872237,0.828224081828896,0.414614123001229,1.1695068569970317,1326.0,147.0,42,10,
