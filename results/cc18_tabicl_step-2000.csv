task_id,dataset_id,dataset_name,n_valid_folds,task_type,metadata,accuracy_mean,accuracy_std,f1_macro_mean,f1_macro_std,f1_micro_mean,f1_micro_std,precision_macro_mean,precision_macro_std,recall_macro_mean,recall_macro_std,roc_auc_mean,roc_auc_std,log_loss_mean,log_loss_std,error
3,3.0,kr-vs-kp,10,Binary,"{'n_samples': 3196, 'n_features': 36, 'n_numeric_features': 0, 'n_categorical_features': 36, 'numeric_feature_names': [], 'categorical_feature_names': ['bkblk', 'bknwy', 'bkon8', 'bkona', 'bkspr', 'bkxbq', 'bkxcr', 'bkxwp', 'blxwp', 'bxqsq', 'cntxt', 'dsopp', 'dwipd', 'hdchk', 'katri', 'mulch', 'qxmsq', 'r2ar8', 'reskd', 'reskr', 'rimmx', 'rkxwp', 'rxmsq', 'simpl', 'skach', 'skewr', 'skrxp', 'spcop', 'stlmt', 'thrsk', 'wkcti', 'wkna8', 'wknck', 'wkovl', 'wkpos', 'wtoeg'], 'n_constant_features': 0, 'n_classes': 2, 'class_labels': ['nowin', 'won'], 'class_counts': {'won': 1669, 'nowin': 1527}, 'majority_class_fraction': 0.522215269086358, 'imbalance_ratio': 1.0929927963326784}",0.9953066222570532,0.0049445109071069035,0.9952982195683931,0.004950478572688046,0.9953066222570532,0.0049445109071069035,0.9953631412370181,0.004926557252541666,0.995312908754215,0.004849217704019182,0.9998586226157604,0.0002322734663857658,0.015857993741842415,0.016905911809806315,
6,,N/A,0,,,,,,,,,,,,,,,,,"HIP out of memory. Tried to allocate 4.83 GiB. GPU 0 has a total capacity of 15.98 GiB of which 3.86 GiB is free. Of the allocated memory 11.70 GiB is allocated by PyTorch, and 86.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
11,11.0,balance-scale,10,Multiclass,"{'n_samples': 625, 'n_features': 4, 'n_numeric_features': 4, 'n_categorical_features': 0, 'numeric_feature_names': ['left-weight', 'left-distance', 'right-weight', 'right-distance'], 'categorical_feature_names': [], 'n_constant_features': 0, 'n_classes': 3, 'class_labels': ['B', 'L', 'R'], 'class_counts': {'B': 49, 'R': 288, 'L': 288}, 'majority_class_fraction': 0.4608, 'imbalance_ratio': 5.877551020408164}",0.9807731694828469,0.014791677602651666,0.9582489343015659,0.029356445883833838,0.9807731694828469,0.014791677602651666,0.9395634920634921,0.03948276432734114,0.9861247947454844,0.010643017869544621,0.997474522944524,0.004411209159354132,0.059935067684531516,0.027669291055242632,
12,12.0,mfeat-factors,10,Multiclass,"{'n_samples': 2000, 'n_features': 216, 'n_numeric_features': 216, 'n_categorical_features': 0, 'numeric_feature_names': ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12', 'att13', 'att14', 'att15', 'att16', 'att17', 'att18', 'att19', 'att20', 'att21', 'att22', 'att23', 'att24', 'att25', 'att26', 'att27', 'att28', 'att29', 'att30', 'att31', 'att32', 'att33', 'att34', 'att35', 'att36', 'att37', 'att38', 'att39', 'att40', 'att41', 'att42', 'att43', 'att44', 'att45', 'att46', 'att47', 'att48', 'att49', 'att50', 'att51', 'att52', 'att53', 'att54', 'att55', 'att56', 'att57', 'att58', 'att59', 'att60', 'att61', 'att62', 'att63', 'att64', 'att65', 'att66', 'att67', 'att68', 'att69', 'att70', 'att71', 'att72', 'att73', 'att74', 'att75', 'att76', 'att77', 'att78', 'att79', 'att80', 'att81', 'att82', 'att83', 'att84', 'att85', 'att86', 'att87', 'att88', 'att89', 'att90', 'att91', 'att92', 'att93', 'att94', 'att95', 'att96', 'att97', 'att98', 'att99', 'att100', 'att101', 'att102', 'att103', 'att104', 'att105', 'att106', 'att107', 'att108', 'att109', 'att110', 'att111', 'att112', 'att113', 'att114', 'att115', 'att116', 'att117', 'att118', 'att119', 'att120', 'att121', 'att122', 'att123', 'att124', 'att125', 'att126', 'att127', 'att128', 'att129', 'att130', 'att131', 'att132', 'att133', 'att134', 'att135', 'att136', 'att137', 'att138', 'att139', 'att140', 'att141', 'att142', 'att143', 'att144', 'att145', 'att146', 'att147', 'att148', 'att149', 'att150', 'att151', 'att152', 'att153', 'att154', 'att155', 'att156', 'att157', 'att158', 'att159', 'att160', 'att161', 'att162', 'att163', 'att164', 'att165', 'att166', 'att167', 'att168', 'att169', 'att170', 'att171', 'att172', 'att173', 'att174', 'att175', 'att176', 'att177', 'att178', 'att179', 'att180', 'att181', 'att182', 'att183', 'att184', 'att185', 'att186', 'att187', 'att188', 'att189', 'att190', 'att191', 'att192', 'att193', 'att194', 'att195', 'att196', 'att197', 'att198', 'att199', 'att200', 'att201', 'att202', 'att203', 'att204', 'att205', 'att206', 'att207', 'att208', 'att209', 'att210', 'att211', 'att212', 'att213', 'att214', 'att215', 'att216'], 'categorical_feature_names': [], 'n_constant_features': 0, 'n_classes': 10, 'class_labels': ['1', '10', '2', '3', '4', '5', '6', '7', '8', '9'], 'class_counts': {'1': 200, '2': 200, '3': 200, '4': 200, '5': 200, '6': 200, '7': 200, '8': 200, '9': 200, '10': 200}, 'majority_class_fraction': 0.1, 'imbalance_ratio': 1.0}",0.984,0.009660917830792967,0.9839869020581473,0.009678741651454822,0.984,0.009660917830792967,0.9846223513328777,0.009274845336665642,0.984,0.009660917830792946,0.9998111111111111,0.0001836977298909127,0.0491394998214509,0.02650045741768337,
14,,N/A,0,,,,,,,,,,,,,,,,,"HIP out of memory. Tried to allocate 3.05 GiB. GPU 0 has a total capacity of 15.98 GiB of which 2.84 GiB is free. Of the allocated memory 12.79 GiB is allocated by PyTorch, and 16.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
15,15.0,breast-w,10,Binary,"{'n_samples': 699, 'n_features': 9, 'n_numeric_features': 9, 'n_categorical_features': 0, 'numeric_feature_names': ['Clump_Thickness', 'Cell_Size_Uniformity', 'Cell_Shape_Uniformity', 'Marginal_Adhesion', 'Single_Epi_Cell_Size', 'Bare_Nuclei', 'Bland_Chromatin', 'Normal_Nucleoli', 'Mitoses'], 'categorical_feature_names': [], 'n_constant_features': 0, 'n_classes': 2, 'class_labels': ['benign', 'malignant'], 'class_counts': {'benign': 458, 'malignant': 241}, 'majority_class_fraction': 0.6552217453505007, 'imbalance_ratio': 1.900414937759336}",0.9699585921325052,0.019573084764947703,0.9668524786394794,0.02158128048071797,0.9699585921325052,0.019573084764947703,0.9666373186157777,0.022438476716156685,0.9681932367149759,0.022651547216383478,0.9940333333333335,0.005668426999002685,0.08783011775835058,0.04645844173840317,
16,16.0,mfeat-karhunen,10,Multiclass,"{'n_samples': 2000, 'n_features': 64, 'n_numeric_features': 64, 'n_categorical_features': 0, 'numeric_feature_names': ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12', 'att13', 'att14', 'att15', 'att16', 'att17', 'att18', 'att19', 'att20', 'att21', 'att22', 'att23', 'att24', 'att25', 'att26', 'att27', 'att28', 'att29', 'att30', 'att31', 'att32', 'att33', 'att34', 'att35', 'att36', 'att37', 'att38', 'att39', 'att40', 'att41', 'att42', 'att43', 'att44', 'att45', 'att46', 'att47', 'att48', 'att49', 'att50', 'att51', 'att52', 'att53', 'att54', 'att55', 'att56', 'att57', 'att58', 'att59', 'att60', 'att61', 'att62', 'att63', 'att64'], 'categorical_feature_names': [], 'n_constant_features': 0, 'n_classes': 10, 'class_labels': ['1', '10', '2', '3', '4', '5', '6', '7', '8', '9'], 'class_counts': {'1': 200, '2': 200, '3': 200, '4': 200, '5': 200, '6': 200, '7': 200, '8': 200, '9': 200, '10': 200}, 'majority_class_fraction': 0.1, 'imbalance_ratio': 1.0}",0.9884999999999999,0.004743416490252573,0.9885362570329134,0.004697108584870285,0.9884999999999999,0.004743416490252573,0.9891826651609259,0.004345896411572092,0.9884999999999999,0.004743416490252561,0.9998444444444443,0.0001343071434405094,0.05255529895200241,0.01842264726133051,
18,18.0,mfeat-morphological,10,Multiclass,"{'n_samples': 2000, 'n_features': 6, 'n_numeric_features': 6, 'n_categorical_features': 0, 'numeric_feature_names': ['att1', 'att2', 'att3', 'att4', 'att5', 'att6'], 'categorical_feature_names': [], 'n_constant_features': 0, 'n_classes': 10, 'class_labels': ['1', '10', '2', '3', '4', '5', '6', '7', '8', '9'], 'class_counts': {'1': 200, '2': 200, '3': 200, '4': 200, '5': 200, '6': 200, '7': 200, '8': 200, '9': 200, '10': 200}, 'majority_class_fraction': 0.1, 'imbalance_ratio': 1.0}",0.748,0.026894857005259103,0.7424173742734961,0.02784957528633258,0.748,0.026894857005259103,0.7487428889545519,0.03332729623664421,0.748,0.02689485700525909,0.9697472222222222,0.006741509546104576,0.5761136754655378,0.08676214675062606,
22,22.0,mfeat-zernike,10,Multiclass,"{'n_samples': 2000, 'n_features': 47, 'n_numeric_features': 47, 'n_categorical_features': 0, 'numeric_feature_names': ['att1', 'att2', 'att3', 'att4', 'att5', 'att6', 'att7', 'att8', 'att9', 'att10', 'att11', 'att12', 'att13', 'att14', 'att15', 'att16', 'att17', 'att18', 'att19', 'att20', 'att21', 'att22', 'att23', 'att24', 'att25', 'att26', 'att27', 'att28', 'att29', 'att30', 'att31', 'att32', 'att33', 'att34', 'att35', 'att36', 'att37', 'att38', 'att39', 'att40', 'att41', 'att42', 'att43', 'att44', 'att45', 'att46', 'att47'], 'categorical_feature_names': [], 'n_constant_features': 0, 'n_classes': 10, 'class_labels': ['1', '10', '2', '3', '4', '5', '6', '7', '8', '9'], 'class_counts': {'1': 200, '2': 200, '3': 200, '4': 200, '5': 200, '6': 200, '7': 200, '8': 200, '9': 200, '10': 200}, 'majority_class_fraction': 0.1, 'imbalance_ratio': 1.0}",0.8875,0.015320646925708545,0.8841056528873589,0.017402961423462062,0.8875,0.015320646925708545,0.8871938322950438,0.017741962385138494,0.8875,0.015320646925708541,0.9904000000000002,0.0021366711285688692,0.23182774409065363,0.038354491548932425,
23,23.0,cmc,10,Multiclass,"{'n_samples': 1473, 'n_features': 9, 'n_numeric_features': 2, 'n_categorical_features': 7, 'numeric_feature_names': ['Wifes_age', 'Number_of_children_ever_born'], 'categorical_feature_names': ['Wifes_education', 'Husbands_education', 'Wifes_religion', 'Wifes_now_working%3F', 'Husbands_occupation', 'Standard-of-living_index', 'Media_exposure'], 'n_constant_features': 0, 'n_classes': 3, 'class_labels': ['1', '2', '3'], 'class_counts': {'1': 629, '2': 333, '3': 511}, 'majority_class_fraction': 0.4270196877121521, 'imbalance_ratio': 1.8888888888888888}",0.5601121529692958,0.0367137399038379,0.5358549860945908,0.043090939446018175,0.5601121529692958,0.0367137399038379,0.5488396930203931,0.04248066361547027,0.5346637672539002,0.042268170929112545,0.7512697875263225,0.031562536798072686,0.8848217898757336,0.049703903479875466,
28,28.0,optdigits,10,Multiclass,"{'n_samples': 5620, 'n_features': 64, 'n_numeric_features': 64, 'n_categorical_features': 0, 'numeric_feature_names': ['input1', 'input2', 'input3', 'input4', 'input5', 'input6', 'input7', 'input8', 'input9', 'input10', 'input11', 'input12', 'input13', 'input14', 'input15', 'input16', 'input17', 'input18', 'input19', 'input20', 'input21', 'input22', 'input23', 'input24', 'input25', 'input26', 'input27', 'input28', 'input29', 'input30', 'input31', 'input32', 'input33', 'input34', 'input35', 'input36', 'input37', 'input38', 'input39', 'input40', 'input41', 'input42', 'input43', 'input44', 'input45', 'input46', 'input47', 'input48', 'input49', 'input50', 'input51', 'input52', 'input53', 'input54', 'input55', 'input56', 'input57', 'input58', 'input59', 'input60', 'input61', 'input62', 'input63', 'input64'], 'categorical_feature_names': [], 'n_constant_features': 2, 'n_classes': 10, 'class_labels': ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], 'class_counts': {'0': 554, '7': 566, '4': 568, '6': 558, '2': 557, '5': 558, '8': 554, '1': 571, '9': 562, '3': 572}, 'majority_class_fraction': 0.10177935943060498, 'imbalance_ratio': 1.032490974729242}",0.9941281138790034,0.002227162912872877,0.9941444180968831,0.0022162553264317305,0.9941281138790034,0.002227162912872877,0.9942831428033448,0.002159943665197308,0.9941254841649577,0.0022323230244838204,0.9999796514498914,2.7752695675038404e-05,0.018243116909367717,0.011138678904437725,
29,29.0,credit-approval,10,Binary,"{'n_samples': 690, 'n_features': 15, 'n_numeric_features': 6, 'n_categorical_features': 9, 'numeric_feature_names': ['A2', 'A3', 'A8', 'A11', 'A14', 'A15'], 'categorical_feature_names': ['A1', 'A4', 'A5', 'A6', 'A7', 'A9', 'A10', 'A12', 'A13'], 'n_constant_features': 0, 'n_classes': 2, 'class_labels': ['+', '-'], 'class_counts': {'+': 307, '-': 383}, 'majority_class_fraction': 0.5550724637681159, 'imbalance_ratio': 1.247557003257329}",0.8797101449275362,0.04044721872257869,0.8783230724076366,0.0404641999430914,0.8797101449275362,0.04044721872257869,0.8792005725428096,0.0415558975652785,0.8784750337381917,0.03957628138578325,0.9428363298651924,0.033616008635224875,0.30690821171742544,0.0937770920548433,
